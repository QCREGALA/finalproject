{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a50f30-671e-4fdd-bac8-6a59aefeca38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36791fdf59d5469eb077b8942d3f1dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter student outcomes (comma-separated):  Focus on Assigned Topic: 4 pts Exemplary Entire essay is related to the assigned topic and allows the reader to understand much more about the topic. 3 pts Proficient Most of the essay is related to the assigned topic. The essay wanders off at one point, but the reader can still learn something about the topic. 2 pts Acceptable Some of the essay is related to the assigned topic, but a reader does not learn much about the topic. 1 pts Beginner No attempt has been made to relate the essay to the assigned topic., Reflection of Personal Learning: 4 pts Exemplary Shows great depth of knowledge and learning, reveals feelings and thoughts, abstract ideas reflected through use of specific details. 3 pts Proficient Relates learning with research and project, personal and general reflections included, uses concrete language. 2 pts Acceptable Does not go deeply into the reflection of learning, generalizations and limited insight, uses some detail. 1 pts Beginner Little or no explanation or reflection on learning, no or few details to support reflection., Organization: 4 pts Exemplary The essay is very well organized. One idea or scene follows another in a logical sequence with clear transitions. 3 pts Proficient The essay is pretty well organized. One idea may seem out of place. Clear transitions are used. 2 pts Acceptable The essay is a little hard to follow. Paragraphs are unclear. The transitions are sometimes not clear. 1 pts Beginner Ideas seem to be randomly arranged. No effort at paragraph organization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter student essays (press Enter on an empty line to submit):\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Define the Internet of Things and describe its key components. Internet of Things is made out of hardware and software systems. Its key components are Sensors, which collects data and sends to the device.  Connectivity, it is the medium between devices to devices can be wifi or  Bluetooth. Next is cloud computing it provides a wide and cost efficient way  to handle large amounts of data that are being generated by IoT devices.\n",
      " What are the primary benefits of implementing IoT in business and industry? One example of the primary benefits of implementing Iot in businesses is that  it has enhanced customer experience, since IOT is very versatile it can provide  the customers their preferred preferences when it comes to the services that  they are applying to.\n",
      " Explain the concept of Edge Computing in IoT and discuss its significance. The importance of edge computing in the Internet of Things resides in its  capacity to get beyond cloud computing's drawbacks, especially in situations  where real-time processing and low latency are crucial. Some of its  significance is enhanced security, since edge computing helps improve the  security on a different level by reducing any sensitive information/data to any  potential threats.\n",
      " \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c7ce89126f45c1a556e054013c0f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n",
      "WARNING:llama_index.llms.huggingface.base:The model `tinyllama-model` and tokenizer `tinyllama-tokenizer` are different, please ensure that they are compatible.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import SimpleDirectoryReader, load_index_from_storage, StorageContext, Settings, VectorStoreIndex\n",
    "\n",
    "import faiss\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "\n",
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pathlib import Path\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tinyllama-tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"tinyllama-model\")\n",
    "\n",
    "# Function to get student outcomes and essays\n",
    "def get_inputs():\n",
    "    student_outcomes = input(\"Enter student outcomes (comma-separated): \").split(\",\")\n",
    "    essays = []\n",
    "    print(\"\\nEnter student essays (press Enter on an empty line to submit):\\n\")\n",
    "    while True:\n",
    "        essay = input()\n",
    "        if not essay:\n",
    "            break\n",
    "        essays.append(essay)\n",
    "    return student_outcomes, essays\n",
    "\n",
    "# Get student outcomes and essays\n",
    "student_outcomes, essays = get_inputs()\n",
    "\n",
    "# Initialize SimpleDirectoryReader with the path to your documents\n",
    "reader = SimpleDirectoryReader(input_files=[\"C:/Users/User/Downloads/IOT.pdf\"])\n",
    "documents = reader.load_data()\n",
    "\n",
    "# Initialize the parser\n",
    "parser = SentenceSplitter.from_defaults(chunk_size=512, chunk_overlap=20)\n",
    "\n",
    "# Parse documents into nodes\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# Initialize Faiss index\n",
    "faiss_index = faiss.IndexFlatL2(768)\n",
    "\n",
    "# Load the embedding model\n",
    "Settings.embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"stsb-distilbert-base\"))\n",
    "\n",
    "# Create a vector storage and its context\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Add the embeddings to the index\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "index.storage_context.persist()\n",
    "\n",
    "# Load index from storage\n",
    "stored_index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Configure LLM\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    context_window=2048,\n",
    "    max_new_tokens=512,\n",
    "    generate_kwargs={\"temperature\": 0.1, \"do_sample\": False},\n",
    "    tokenizer_name=\"tinyllama-tokenizer\",\n",
    "    model_name=\"tinyllama-model\",\n",
    "    tokenizer_kwargs={\"max_length\": 2048},\n",
    "    model_kwargs={\"torch_dtype\": torch.float16}\n",
    ")\n",
    "\n",
    "# Function to calculate relevance score\n",
    "def calculate_relevance(nodes, outcome):\n",
    "    # Implement your relevance scoring logic here\n",
    "    # For example, you can calculate relevance based on the number of relevant nodes\n",
    "    relevant_nodes = [node for node in nodes if outcome in node.node.get_text()]\n",
    "    relevance_score = len(relevant_nodes) / len(nodes) if len(nodes) > 0 else 0\n",
    "    return relevance_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010811dc-cb0e-44ec-8f0e-937536a51e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the model with the essays\n",
    "grades = {}\n",
    "for outcome in student_outcomes:\n",
    "    for essay in essays:\n",
    "        query_engine = stored_index.as_query_engine()\n",
    "        response = query_engine.query(essay)\n",
    "\n",
    "        # Get the retrieved nodes\n",
    "        nodes = response.source_nodes\n",
    "\n",
    "        # Your grading code goes here, integrating with the retrieved nodes\n",
    "        relevance_score = calculate_relevance(nodes, outcome)\n",
    "        # Assign grades based on the relevance score\n",
    "        if relevance_score >= 0.8:\n",
    "            grades[(outcome, essay)] = \"High\"\n",
    "        elif relevance_score >= 0.5:\n",
    "            grades[(outcome, essay)] = \"Medium\"\n",
    "        else:\n",
    "            grades[(outcome, essay)] = \"Low\"\n",
    "\n",
    "# Provide feedback based on the grades\n",
    "for (outcome, essay), grade in grades.items():\n",
    "    feedback = f\"Outcome: {outcome}\\nEssay: {essay}\\nGrade: {grade}\\nFeedback: \"\n",
    "    if grade == \"High\":\n",
    "        feedback += \"Well done! Your essay demonstrates excellent skills in this area.\"\n",
    "    elif grade == \"Medium\":\n",
    "        feedback += \"Good effort! Your essay shows some skills in this area, but there is room for improvement.\"\n",
    "    else:\n",
    "        feedback += \"There is room for improvement. Your essay lacks sufficient evidence of skills in this area.\"\n",
    "    print(feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1dea12-76d8-4c5b-b429-78de57d67e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
